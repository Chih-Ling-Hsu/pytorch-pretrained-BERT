{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/amy/.local/lib/python3.5/site-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /home/amy/.local/lib/python3.5/site-packages (from pytorch-pretrained-bert) (4.28.1)\n",
      "Collecting regex (from pytorch-pretrained-bert)\n",
      "Requirement already satisfied: numpy in /home/amy/.local/lib/python3.5/site-packages (from pytorch-pretrained-bert) (1.16.2)\n",
      "Requirement already satisfied: boto3 in /home/amy/.local/lib/python3.5/site-packages (from pytorch-pretrained-bert) (1.9.86)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/amy/.local/lib/python3.5/site-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/amy/.local/lib/python3.5/site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amy/.local/lib/python3.5/site-packages (from requests->pytorch-pretrained-bert) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/amy/.local/lib/python3.5/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/amy/.local/lib/python3.5/site-packages (from requests->pytorch-pretrained-bert) (1.24.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/amy/.local/lib/python3.5/site-packages (from boto3->pytorch-pretrained-bert) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.86 in /home/amy/.local/lib/python3.5/site-packages (from boto3->pytorch-pretrained-bert) (1.12.86)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/amy/.local/lib/python3.5/site-packages (from boto3->pytorch-pretrained-bert) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/amy/.local/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.86->boto3->pytorch-pretrained-bert) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/amy/.local/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.86->boto3->pytorch-pretrained-bert) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/amy/.local/lib/python3.5/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.86->boto3->pytorch-pretrained-bert) (1.12.0)\n",
      "Installing collected packages: regex, pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.1 regex-2019.3.12\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytorch-pretrained-bert --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Cross Validation\n",
    "\n",
    "```shell\n",
    "python3 examples/run_classifier.py \n",
    "    --task_name OPM-2 \n",
    "    --bert_model bert-base-uncased\n",
    "    --data_dir data/OPM-2/cv$1 --output_dir output/opm2_output/\n",
    "    --do_lower_case  --max_seq_length 140 \n",
    "    --do_train\n",
    "    --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 \n",
    "    --device 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv0 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "05/03/2019 17:58:06 - INFO - __main__ -   ***** Eval results *****\n",
    "05/03/2019 17:58:06 - INFO - __main__ -     eval_accuracy = 0.8574190023952599\n",
    "05/03/2019 17:58:06 - INFO - __main__ -     eval_loss = 0.42036889072664146\n",
    "05/03/2019 17:58:06 - INFO - __main__ -     global_step = 26772\n",
    "05/03/2019 17:58:06 - INFO - __main__ -     loss = 0.1636066984320687\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv1 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/19/2019 15:46:55 - INFO - __main__ -   ***** Eval results *****\n",
    "04/19/2019 15:46:55 - INFO - __main__ -     eval_accuracy = 0.8673560882300198\n",
    "04/19/2019 15:46:55 - INFO - __main__ -     eval_loss = 0.4010059461051003\n",
    "04/19/2019 15:46:55 - INFO - __main__ -     global_step = 18820\n",
    "04/19/2019 15:46:55 - INFO - __main__ -     loss = 0.14872505419850982\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "05/03/2019 18:02:53 - INFO - __main__ -   device: cuda n_gpu: 2, distributed training: False, 16-bits training: False\n",
      "05/03/2019 18:02:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/amy/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/03/2019 18:02:56 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/amy/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/03/2019 18:02:56 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/amy/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp5o1kr3nz\n",
      "05/03/2019 18:03:00 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv2 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/19/2019 17:51:43 - INFO - __main__ -   ***** Eval results *****\n",
    "04/19/2019 17:51:43 - INFO - __main__ -     eval_accuracy = 0.8634706198816426\n",
    "04/19/2019 17:51:43 - INFO - __main__ -     eval_loss = 0.4321577670907399\n",
    "04/19/2019 17:51:43 - INFO - __main__ -     global_step = 18820\n",
    "04/19/2019 17:51:43 - INFO - __main__ -     loss = 0.14989937140540033\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 22, in <module>\r\n",
      "    import logging\r\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 26, in <module>\r\n",
      "    import sys, os, time, io, traceback, warnings, weakref, collections\r\n",
      "  File \"/usr/lib/python3.5/traceback.py\", line 5, in <module>\r\n",
      "    import linecache\r\n",
      "  File \"/usr/lib/python3.5/linecache.py\", line 11, in <module>\r\n",
      "    import tokenize\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 765, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 476, in _compile_bytecode\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv3 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/19/2019 19:56:32 - INFO - __main__ -   ***** Eval results *****\n",
    "04/19/2019 19:56:32 - INFO - __main__ -     eval_accuracy = 0.8635303963177715\n",
    "04/19/2019 19:56:32 - INFO - __main__ -     eval_loss = 0.4164111155279365\n",
    "04/19/2019 19:56:32 - INFO - __main__ -     global_step = 18820\n",
    "04/19/2019 19:56:32 - INFO - __main__ -     loss = 0.1501456702395276\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv4 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/19/2019 22:01:10 - INFO - __main__ -   ***** Eval results *****\n",
    "04/19/2019 22:01:10 - INFO - __main__ -     eval_accuracy = 0.8597047044055234\n",
    "04/19/2019 22:01:10 - INFO - __main__ -     eval_loss = 0.42836336084564947\n",
    "04/19/2019 22:01:10 - INFO - __main__ -     global_step = 18820\n",
    "04/19/2019 22:01:10 - INFO - __main__ -     loss = 0.14923250691789053\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 27, in <module>\r\n",
      "    import numpy as np\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/__init__.py\", line 142, in <module>\r\n",
      "    from . import core\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/__init__.py\", line 40, in <module>\r\n",
      "    from . import multiarray\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/multiarray.py\", line 12, in <module>\r\n",
      "    from . import overrides\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/overrides.py\", line 8, in <module>\r\n",
      "    from numpy.compat._inspect import getargspec\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/__init__.py\", line 14, in <module>\r\n",
      "    from . import py3k\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/py3k.py\", line 15, in <module>\r\n",
      "    from pathlib import Path, PurePath\r\n",
      "  File \"/usr/lib/python3.5/pathlib.py\", line 14, in <module>\r\n",
      "    from urllib.parse import quote_from_bytes as urlquote_from_bytes\r\n",
      "  File \"/usr/lib/python3.5/urllib/parse.py\", line 269, in <module>\r\n",
      "    class ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv5 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/20/2019 00:05:48 - INFO - __main__ -   ***** Eval results *****\n",
    "04/20/2019 00:05:48 - INFO - __main__ -     eval_accuracy = 0.8635140790338973\n",
    "04/20/2019 00:05:48 - INFO - __main__ -     eval_loss = 0.4354025022118272\n",
    "04/20/2019 00:05:48 - INFO - __main__ -     global_step = 18820\n",
    "04/20/2019 00:05:48 - INFO - __main__ -     loss = 0.14831425988023328\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 27, in <module>\r\n",
      "    import numpy as np\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/__init__.py\", line 142, in <module>\r\n",
      "    from . import core\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/__init__.py\", line 93, in <module>\r\n",
      "    from . import numerictypes as nt\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/numerictypes.py\", line 111, in <module>\r\n",
      "    from ._type_aliases import (\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/_type_aliases.py\", line 178, in <module>\r\n",
      "    _add_integer_aliases()\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/_type_aliases.py\", line 173, in _add_integer_aliases\r\n",
      "    sctypeNA[info.type] = Intname\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv6 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/20/2019 02:10:27 - INFO - __main__ -   ***** Eval results *****\n",
    "04/20/2019 02:10:27 - INFO - __main__ -     eval_accuracy = 0.8657260716207329\n",
    "04/20/2019 02:10:27 - INFO - __main__ -     eval_loss = 0.41811771826602123\n",
    "04/20/2019 02:10:27 - INFO - __main__ -     global_step = 18820\n",
    "04/20/2019 02:10:27 - INFO - __main__ -     loss = 0.15115820528953222\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 27, in <module>\r\n",
      "    import numpy as np\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/__init__.py\", line 142, in <module>\r\n",
      "    from . import core\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/__init__.py\", line 40, in <module>\r\n",
      "    from . import multiarray\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/multiarray.py\", line 12, in <module>\r\n",
      "    from . import overrides\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/overrides.py\", line 8, in <module>\r\n",
      "    from numpy.compat._inspect import getargspec\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/__init__.py\", line 14, in <module>\r\n",
      "    from . import py3k\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/py3k.py\", line 15, in <module>\r\n",
      "    from pathlib import Path, PurePath\r\n",
      "  File \"/usr/lib/python3.5/pathlib.py\", line 14, in <module>\r\n",
      "    from urllib.parse import quote_from_bytes as urlquote_from_bytes\r\n",
      "  File \"/usr/lib/python3.5/urllib/parse.py\", line 228, in <module>\r\n",
      "    _SplitResultBase = namedtuple('SplitResult', 'scheme netloc path query fragment')\r\n",
      "  File \"/usr/lib/python3.5/collections/__init__.py\", line 439, in namedtuple\r\n",
      "    result.__module__ = _sys._getframe(1).f_globals.get('__name__', '__main__')\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv7 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/20/2019 04:15:06 - INFO - __main__ -   ***** Eval results *****\n",
    "04/20/2019 04:15:06 - INFO - __main__ -     eval_accuracy = 0.8652397465024513\n",
    "04/20/2019 04:15:06 - INFO - __main__ -     eval_loss = 0.42009574580725617\n",
    "04/20/2019 04:15:06 - INFO - __main__ -     global_step = 18820\n",
    "04/20/2019 04:15:06 - INFO - __main__ -     loss = 0.14927537678112449\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 27, in <module>\r\n",
      "    import numpy as np\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/__init__.py\", line 142, in <module>\r\n",
      "    from . import core\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/__init__.py\", line 40, in <module>\r\n",
      "    from . import multiarray\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/multiarray.py\", line 12, in <module>\r\n",
      "    from . import overrides\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/core/overrides.py\", line 8, in <module>\r\n",
      "    from numpy.compat._inspect import getargspec\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/__init__.py\", line 14, in <module>\r\n",
      "    from . import py3k\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/numpy/compat/py3k.py\", line 15, in <module>\r\n",
      "    from pathlib import Path, PurePath\r\n",
      "  File \"/usr/lib/python3.5/pathlib.py\", line 14, in <module>\r\n",
      "    from urllib.parse import quote_from_bytes as urlquote_from_bytes\r\n",
      "  File \"/usr/lib/python3.5/urllib/parse.py\", line 227, in <module>\r\n",
      "    _DefragResultBase = namedtuple('DefragResult', 'url fragment')\r\n",
      "  File \"/usr/lib/python3.5/collections/__init__.py\", line 428, in namedtuple\r\n",
      "    exec(class_definition, namespace)\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv8 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/20/2019 06:20:20 - INFO - __main__ -   ***** Eval results *****\n",
    "04/20/2019 06:20:20 - INFO - __main__ -     eval_accuracy = 0.8665988997847405\n",
    "04/20/2019 06:20:20 - INFO - __main__ -     eval_loss = 0.42137531934208927\n",
    "04/20/2019 06:20:20 - INFO - __main__ -     global_step = 18820\n",
    "04/20/2019 06:20:20 - INFO - __main__ -     loss = 0.14981252964780004\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "05/03/2019 18:03:10 - INFO - __main__ -   device: cuda n_gpu: 2, distributed training: False, 16-bits training: False\n",
      "05/03/2019 18:03:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/amy/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/03/2019 18:03:12 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/amy/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/03/2019 18:03:12 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/amy/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpr7ytsuoc\n",
      "05/03/2019 18:03:16 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_output/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_eval --do_lower_case --data_dir data/OPM-2/cv9 --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_output/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "04/20/2019 08:24:54 - INFO - __main__ -   ***** Eval results *****\n",
    "04/20/2019 08:24:54 - INFO - __main__ -     eval_accuracy = 0.8636689787132265\n",
    "04/20/2019 08:24:54 - INFO - __main__ -     eval_loss = 0.41801546670991746\n",
    "04/20/2019 08:24:54 - INFO - __main__ -     global_step = 18820\n",
    "04/20/2019 08:24:54 - INFO - __main__ -     loss = 0.14945458588759464\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation score: 0.8646643884209057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full Training Set\n",
    "\n",
    "```sh\n",
    "python3 examples/run_classifier.py \n",
    "    --task_name OPM-2 \n",
    "    --bert_model bert-base-uncased\n",
    "    --data_dir data/OPM-2/full --output_dir output/opm2_output/\n",
    "    --do_lower_case  --max_seq_length 140 \n",
    "    --do_train\n",
    "    --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 \n",
    "    --device 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"examples/run_classifier.py\", line 28, in <module>\r\n",
      "    import torch\r\n",
      "  File \"/home/amy/.local/lib/python3.5/site-packages/torch/__init__.py\", line 80, in <module>\r\n",
      "    import torch._nvrtc\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 954, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 896, in _find_spec\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1139, in find_spec\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1113, in _get_spec\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1252, in find_spec\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1211, in _get_spec\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 893, in __init__\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_model/\n",
    "!python3 examples/run_classifier.py --task_name OPM-2 --do_train --do_lower_case --data_dir data/OPM-2/full --bert_model bert-base-uncased --max_seq_length 140 --train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --output_dir output/opm2_model/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict bullish/bearish proba on `Twits`\n",
    "\n",
    "\n",
    "```sh\n",
    "python3 examples/opinion_mining.py\n",
    "  --task_name OPM-2\n",
    "  --bert_model bert-base-uncased --resume output/opm2_output\n",
    "  --data_dir data/OPM-2/twits -output_dir output/opm2_twits/\n",
    "  --do_lower_case --max_seq_length 140\n",
    "  --device 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 303\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mexec_err_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6cfe06caa460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf output/opm2_twits/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 examples/opinion_mining.py --task_name OPM-2 --do_lower_case --data_dir data/OPM-2/twits --bert_model bert-base-uncased --resume output/opm2_output --max_seq_length 140 --output_dir output/opm2_twits/ -d 0,1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "!rm -rf output/opm2_twits/\n",
    "!python3 examples/opinion_mining.py --task_name OPM-2 --do_lower_case --data_dir data/OPM-2/twits --bert_model bert-base-uncased --resume output/opm2_output --max_seq_length 140 --output_dir output/opm2_twits/ -d 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict bullish/bearish proba on `Tweets`\n",
    "\n",
    "\n",
    "```sh\n",
    "python3 examples/opinion_mining.py\n",
    "  --task_name OPM-2\n",
    "  --bert_model bert-base-uncased --resume output/opm2_output\n",
    "  --data_dir data/OPM-2/tweets -output_dir output/opm2_tweets/\n",
    "  --do_lower_case --max_seq_length 140\n",
    "  --device 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output/opm2_tweets/\n",
    "!python3 examples/opinion_mining.py --task_name OPM-2 --do_lower_case --data_dir data/OPM-2/tweets --bert_model bert-base-uncased --resume output/opm2_output --max_seq_length 140 --output_dir output/opm2_tweets/ -d 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
